<h3 align="left">Hi ğŸ‘‹ I'm Chika Maduabuchi, an AI researcher working on video generation and understanding</h3>

<h3 align="left">ğŸš€ Ongoing/Completed Projects</h3>

1) **CAT-LVDM**: *Robust Video Diffusion via Structured Corruption* <br>
ğŸ“ NeurIPS 2025 (under review) Â· [ğŸ“„ arXiv](https://arxiv.org/abs/2505.21545) Â· [ğŸ§  Code](https://github.com/chikap421/catlvdm) Â· [ğŸ¤— Checkpoints](https://huggingface.co/Chikap421/catlvdm-checkpoints/tree/main)

<div align="center">
  <img src="assets/catlvdm.png" width="500"/>
</div>

---

2) **VideoSAM**: *A large vision foundation model for high-speed video segmentation** <br>
ğŸ“ IEEE SSD 2025 Â· [ğŸ“„ arXiv](https://arxiv.org/abs/2410.21304) Â· [ğŸ§  Code](https://github.com/chikap421/videosam)

<div align="center">
  <img src="assets/videosam_teaser_plot.png" width="500"/>
</div>

---

3) **AfriInstruct**: *Instruction tuning of African languages for diverse NLP tasks* <br>
ğŸ“ EMNLP 2024 Â· [ğŸ“„ Paper](https://aclanthology.org/2024.findings-emnlp.793/) Â· [ğŸ§  Code](https://github.com/chikap421/AfriInstruct)

<div align="center">
  <img src="assets/afriinstruct_teaser.png" width="500"/>
</div>


---

<h3 align="left">ğŸ”— Links</h3>

- ğŸ‘¨â€ğŸ“ Google Scholar: [scholar.google.com/citations?user=YrLydoQAAAAJ](https://scholar.google.com/citations?user=YrLydoQAAAAJ&hl=en)  
- ğŸ“§ Email: [chikap421@gmail.com](mailto:chikap421@gmail.com)  
- ğŸ”— LinkedIn: [linkedin.com/in/mchika](https://www.linkedin.com/in/mchika/)  
- ğŸ§  Hugging Face: [huggingface.co/Chikap421](https://huggingface.co/Chikap421)  
